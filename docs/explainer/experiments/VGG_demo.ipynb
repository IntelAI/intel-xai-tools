{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c8d168-82fc-44a1-9f7f-05de20661eb4",
   "metadata": {},
   "source": [
    "# VGG16 RAVDESS Walkthrough using explainer\n",
    "Pulled from Muriel Kosaka's following articles:\\\n",
    "https://towardsdatascience.com/speech-emotion-recognition-using-ravdess-audio-dataset-ce19d162690\\\n",
    "https://towardsdatascience.com/fine-tuning-pre-trained-model-vgg-16-1277268c537f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcbd0f2-c88d-4a56-8460-d296a0c198b8",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "#### 1. Data exploration \n",
    "#### 2. Dataset generation\n",
    "#### 2. Load the trained VGG16\n",
    "#### 3. Implement the metrics explainer plugin\n",
    "#### 4. Implmenet the deep explainer\n",
    "#### 5. Implement the gradient explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0868a797-1fbf-4851-ab40-49105d5cbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT NECESSARY LIBRARIES\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import PIL\n",
    "#import librosa\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "#import librosa.display\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import os # interface with underlying OS that python is running on\n",
    "import sys\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "# if on Intel AI kit env run:\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# in not on Intel AI kit env run:\n",
    "#from keras.optimizers import SGD\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from keras.regularizers import l2\n",
    "#import seaborn as sns\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23196c39-d448-41ec-849f-f34e0a19bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to where your dataset is\n",
    "dataset_path = '../../../../data'\n",
    "train_dir = '../../../../train_logmel'\n",
    "\n",
    "\n",
    "# LOAD IN FILE\n",
    "import librosa\n",
    "from librosa.display import waveshow\n",
    "happy, sr = librosa.load(os.path.join(dataset_path,'03-01-03-01-01-02-01.wav'))\n",
    "sad, sr = librosa.load(os.path.join(dataset_path,'03-01-04-01-01-02-01.wav'))\n",
    "# PLAY AUDIO FILE\n",
    "#librosa.write_wav('ipd.Audio Files/MaleNeutral.wav', x, sr)\n",
    "# DISPLAY WAVEPLOT\n",
    "plt.figure(figsize=(8, 4))\n",
    "waveshow(happy, sr=sr)\n",
    "plt.title('Waveplot - Male Happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef585f-5a58-422c-808d-e83f4e141259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE LOG MEL SPECTROGRAM\n",
    "spectrogram = librosa.feature.melspectrogram(y=happy, sr=sr, n_mels=128,fmax=8000) \n",
    "spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\n",
    "plt.title('Mel Spectrogram - Male Happy')\n",
    "plt.colorbar(format='%+2.0f dB');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35669bfd-9289-4020-851d-0b2200d444cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=happy, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf9521-6c79-41fa-97d5-20d0e8de72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY WAVEPLOT\n",
    "plt.figure(figsize=(8, 4))\n",
    "waveshow(sad, sr=sr)\n",
    "plt.title('Waveplot - Male Sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46069e-accc-48f2-b576-7eec51ae4488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE LOG MEL SPECTROGRAM\n",
    "spectrogram = librosa.feature.melspectrogram(y=sad, sr=sr, n_mels=128,fmax=8000) \n",
    "spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\n",
    "plt.title('Mel Spectrogram - Male Sad')\n",
    "plt.colorbar(format='%+2.0f dB');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f3d19-3f2e-45d8-9b3d-107c3d10c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=sad, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a5b349-b7a5-4dea-b635-6c7926a50e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect samples for training/validation\n",
    "\n",
    "import glob\n",
    "angry = glob.glob(os.path.join(train_dir,'angry/*.*'))\n",
    "calm = glob.glob(os.path.join(train_dir,'calm/*.*'))\n",
    "disgust = glob.glob(os.path.join(train_dir,'disgust/*.*'))\n",
    "fearful = glob.glob(os.path.join(train_dir,'fear/*.*'))\n",
    "happy = glob.glob(os.path.join(train_dir,'happy/*.*'))\n",
    "neutral = glob.glob(os.path.join(train_dir,'neutral/*.*'))\n",
    "sad = glob.glob(os.path.join(train_dir,'sad/*.*'))\n",
    "surprised = glob.glob(os.path.join(train_dir,'surprise/*.*'))\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for i in angry:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append('Angry')\n",
    "for i in calm:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append('Calm')\n",
    "for i in disgust:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append('Disgust')\n",
    "for i in fearful:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append('Fearful')\n",
    "for i in happy:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append('Happy')\n",
    "for i in neutral:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append('Neutral')\n",
    "for i in sad:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append('Sad')\n",
    "for i in surprised:\n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append('Surprised')\n",
    "    \n",
    "    \n",
    "# random split the 80/20 train/val examples\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(np.array(data), np.array(labels),\n",
    "                                                  test_size=0.2, random_state=0)\n",
    "train_labels = y_train\n",
    "val_labels = y_val\n",
    "# normalize\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "\n",
    "# one-hot encode classes\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "y_train = to_categorical(lb.fit_transform(y_train))\n",
    "y_val = to_categorical(lb.fit_transform(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c6077-bae8-4d19-bcf5-1a96761e952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "clf = tf.keras.models.load_model('../../../../no_aug_VGG_TL.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31da75-cb1b-4612-9015-e5c5a0691e05",
   "metadata": {},
   "source": [
    "# Explainer plugins "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d55a6b-e30a-4160-acbd-72fb9dc7f694",
   "metadata": {},
   "source": [
    "### metrics_explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85e79b-3c19-4c20-9834-2132b0038ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00baee5-51c1-4d2a-b242-8748dcfdf9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainer.explainers import metrics_explainer\n",
    "cm = metrics_explainer['confusionmatrix'](y_val, y, lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dbd0b7-1bc2-4b25-a2a4-2dc3cd2cfe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eea6f5-a62c-4390-969b-2274e06b9773",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f42d880-9aac-4cc4-81fb-1b9572688ca9",
   "metadata": {},
   "source": [
    "### GradientExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0d950-7123-4d82-8437-127ac9d6ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "[happy_i, sad_i] = lb.transform(['Happy', 'Sad'])\n",
    "happy_indxs = []\n",
    "sad_indxs = []\n",
    "for i, ex in enumerate(y_val):\n",
    "    if ex[happy_i] == 1:\n",
    "        happy_indxs.append(i)\n",
    "    elif ex[sad_i] == 1:\n",
    "        sad_indxs.append(i)\n",
    "background = np.delete(X_val, happy_indxs,0)\n",
    "test_images = X_val[happy_indxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121fc1f9-efc0-48e4-82a0-bcd82837ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainer.explainers import feature_attributions_explainer\n",
    "gradientexplainer =  feature_attributions_explainer['gradientexplainer']\n",
    "gaViz = gradientexplainer(clf,background[:20],test_images[:3],3,lb)\n",
    "gaViz.visualize(test_images[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384050b5-932b-4041-a02a-821848e5e361",
   "metadata": {},
   "source": [
    "### DeepExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf43ef-d9bc-4992-9195-9dd7dcd78c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainer.explainers import feature_attributions_explainer\n",
    "deepexplainer =  feature_attributions_explainer['deepexplainer']\n",
    "deViz = deepexplainer(clf,background[:2],test_images[:3],lb)\n",
    "deViz.visualize(test_images[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
