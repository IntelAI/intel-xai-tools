{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Language Model Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the [ecco toolkit](https://ecco.readthedocs.io/en/main/){cite}`alammar-2021-ecco`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainer.explainers import lm_layers_explainer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['KMP_WARNINGS'] = 'off'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_layers_explainer.entry_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show activations in each layer in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'bert-base-uncased'\n",
    "text = ''' \n",
    "Now I ask you: what can be expected of man since he is a being endowed with strange qualities? \n",
    "Shower upon him every earthly blessing, drown him in a sea of happiness, so that nothing but bubbles of bliss \n",
    "can be seen on the surface; give him economic prosperity, such that he should have nothing else to do but sleep, \n",
    "eat cakes and busy himself with the continuation of his species, and even then out of sheer ingratitude, sheer spite, \n",
    "man would play you some nasty trick. He would even risk his cakes and would deliberately desire the most fatal rubbish, \n",
    "the most uneconomical absurdity, simply to introduce into all this positive good sense his fatal fantastic element. \n",
    "It is just his fantastic dreams, his vulgar folly that he will desire to retain, simply in order to prove to himself--as though that were so necessary-- \n",
    "that men still are men and not the keys of a piano, which the laws of nature threaten to control so completely that soon one will be able to desire nothing but by the calendar. \n",
    "And that is not all: even if man really were nothing but a piano-key, even if this were proved to him by natural science and mathematics, even then he would not become reasonable,\n",
    "but would purposely do something perverse out of simple ingratitude, simply to gain his point. And if he does not find means he will contrive destruction and chaos, will \n",
    "contrive sufferings of all sorts, only to gain his point! He will launch a curse upon the world, and as only man can curse (it is his privilege, the primary distinction \n",
    "between him and other animals), may be by his curse alone he will attain his object--that is, convince himself that he is a man and not a piano-key!\n",
    "'''\n",
    "activations = lm_layers_explainer['activations'](model, text)\n",
    "activations(n_components=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in the blank: \"Heathrow airport is located in the city of __\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'distilgpt2'\n",
    "text = \" Heathrow airport is in the city of\"\n",
    "predictions = lm_layers_explainer['predictions'](model, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the candidate tokens at the last layer of the model (layer 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions(position=8, layer=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see more tokens using the topk parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions(position=8, layer=5, topk=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the candidate tokens at every layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions(position=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show rankings for the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'distilgpt2'\n",
    "text = \"The keys to the cabinet\"\n",
    "rankings = lm_layers_explainer['rankings'](model)\n",
    "rankings(text, generate=1, do_sample=False).rankings_watch(watch=[318, 389], position=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention head view\n",
    "\n",
    "### Usage\n",
    "- Hover over any token on the left/right side of the visualization to filter attention from/to that token. The colors correspond to different attention heads.\n",
    "- Double-click on any of the colored tiles at the top to filter to the corresponding attention head.\n",
    "- Single-click on any of the colored tiles to toggle selection of the corresponding attention head.\n",
    "- Click on the Layer drop-down to change the model layer (zero-indexed).\n",
    "- The lines show the attention from each token (left) to every other token (right). Darker lines indicate higher attention weights. When multiple heads are selected, the attention weights are overlaid on one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'bert-base-uncased'\n",
    "text = \"The cat sat on the mat\"\n",
    "print(lm_layers_explainer['attention_head_view'].__doc__)\n",
    "head_view = lm_layers_explainer['attention_head_view'](model)\n",
    "\n",
    "head_view(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'bert-base-uncased'\n",
    "sentence_a = \"The cat sat on the mat\"\n",
    "sentence_b = \"The cat lay on the rug\"\n",
    "neuron_view = lm_layers_explainer['attention_neuron_view'](model)\n",
    "neuron_view(sentence_a, sentence_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'facebook/bart-large-cnn'\n",
    "sentence_a = \"The House Budget Committee voted Saturday to pass a $3.5 trillion spending bill\"\n",
    "sentence_b = \"The House Budget Committee passed a spending bill.\"\n",
    "model_view = lm_layers_explainer['attention_model_view'](model)\n",
    "model_view(sentence_a, sentence_b)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "orphan": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "47de4e6fcdf76d9f7e9823221d58331110ca8a86e4fcaa17b27f269bc08adee8"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
