{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing explainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntryPoint(name='deepexplainer', value='feature_attributions_explainer:deep_explainer [labels,targetimages,backgroundimages,model]', group='explainer.explainers.feature_attributions_explainer')\n",
      "EntryPoint(name='deeplift', value='feature_attributions_explainer:deeplift [model]', group='explainer.explainers.feature_attributions_explainer')\n",
      "EntryPoint(name='gradientexplainer', value='feature_attributions_explainer:gradient_explainer', group='explainer.explainers.feature_attributions_explainer')\n",
      "EntryPoint(name='integratedgradients', value='feature_attributions_explainer:integratedgradients [model]', group='explainer.explainers.feature_attributions_explainer')\n",
      "EntryPoint(name='kernelexplainer', value='feature_attributions_explainer:kernel_explainer [data,model]', group='explainer.explainers.feature_attributions_explainer')\n"
     ]
    }
   ],
   "source": [
    "# intel-tensorflow==2.9.1\n",
    "# shap @ git+https://github.com/slundberg/shap@v0.41.0\n",
    "from explainer.explainers import feature_attributions_explainer, metrics_explainer\n",
    "feature_attributions_explainer.entry_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog10.png'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('nateraw/vit-base-patch16-224-cifar10')\n",
    "model = ViTForImageClassification.from_pretrained('nateraw/vit-base-patch16-224-cifar10')\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "preds = outputs.logits.argmax(dim=1)\n",
    "\n",
    "classes = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "classes[preds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_datasets, load_dataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[1;32m      4\u001b[0m datasets_list \u001b[38;5;241m=\u001b[39m list_datasets() \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import list_datasets, load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "datasets_list = list_datasets() \n",
    "pprint(datasets_list,compact=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images/dog10.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 19:19:37.971044: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=1\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   KMP_WARNINGS=0\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=448\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=1\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_ENABLE_TASK_THROTTLING=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=112\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=false\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=1\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "   OMP_NUM_THREADS: value is not defined\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2022-09-30 19:19:37.976929: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast, BasicTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import shap\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "    tv = torch.tensor([tokenizer.encode(v, padding='max_length', max_length=128, truncation=True) for v in x])\n",
    "    attention_mask = (tv!=0).type(torch.int64)\n",
    "    logit_arr = model(tv,attention_mask=attention_mask).logits.detach().cpu().numpy()\n",
    "    scores = sp.special.expit(logit_arr)\n",
    "    return scores\n",
    "\n",
    "def custom_tokenizer(text, return_offsets_mapping=True):\n",
    "    text = text.lower()\n",
    "    wordpunct = BasicTokenizer()\n",
    "    splitted_text_list = wordpunct.tokenize(text)\n",
    "    pos_list = []\n",
    "    pos=0\n",
    "    for item in splitted_text_list: \n",
    "      start = text.find(item, pos)\n",
    "      end = start + len(item)\n",
    "      pos_list.append((start, end))\n",
    "      pos = end\n",
    "    out={}\n",
    "    out[\"input_ids\"] = splitted_text_list\n",
    "    if return_offsets_mapping: \n",
    "      out['offset_mapping']=pos_list\n",
    "    return out\n",
    "\n",
    "masker = shap.maskers.Text(custom_tokenizer)\n",
    "masker.mask_token = ''\n",
    "explainer = shap.Explainer(f, masker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(X[:100])\n",
    "\n",
    "# plot the SHAP values for the positive class\n",
    "shap.plots.beeswarm(shap_values[...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>function calls</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  function calls   time\n",
       "0            124  0.000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%script false --no-raise-error\n",
    "\n",
    "from explainer.explainers import metrics_explainer\n",
    "\n",
    "pstats = metrics_explainer['pstats']('explainer = shap.Explainer(f, masker)')\n",
    "pstats.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncalls</th>\n",
       "      <th>tottime</th>\n",
       "      <th>percall</th>\n",
       "      <th>cumtime</th>\n",
       "      <th>percall</th>\n",
       "      <th>filename:lineno(function)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>_explainer.py:27(__init__)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>method builtins.exec}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>_general.py:174(safe_isinstance)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>method builtins.getattr}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>_partition.py:27(__init__)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>method builtins.isinstance}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>'rsplit' of 'str' objects}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>&lt;string&gt;:1(&lt;module&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>_linear.py:269(supports_model_with_masker)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>transformers.py:86(is_transformers_lm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>_model.py:14(__init__)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>_tree.py:546(supports_model_with_masker)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>method builtins.hasattr}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>_base.py:1301(isspmatrix)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>_additive.py:78(supports_model_with_masker)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>method builtins.callable}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>'disable' of '_lsprof.Profiler' objects}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>method builtins.issubclass}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>method builtins.len}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ncalls tottime percall cumtime percall  \\\n",
       "0     2/1   0.000   0.000   0.000   0.000   \n",
       "1       1   0.000   0.000   0.000   0.000   \n",
       "2      18   0.000   0.000   0.000   0.000   \n",
       "3      19   0.000   0.000   0.000   0.000   \n",
       "4       1   0.000   0.000   0.000   0.000   \n",
       "5      42   0.000   0.000   0.000   0.000   \n",
       "6      20   0.000   0.000   0.000   0.000   \n",
       "7       1   0.000   0.000   0.000   0.000   \n",
       "8       1   0.000   0.000   0.000   0.000   \n",
       "9       2   0.000   0.000   0.000   0.000   \n",
       "10      1   0.000   0.000   0.000   0.000   \n",
       "11      1   0.000   0.000   0.000   0.000   \n",
       "12      3   0.000   0.000   0.000   0.000   \n",
       "13      2   0.000   0.000   0.000   0.000   \n",
       "14      1   0.000   0.000   0.000   0.000   \n",
       "15      5   0.000   0.000   0.000   0.000   \n",
       "16      1   0.000   0.000   0.000   0.000   \n",
       "17      2   0.000   0.000   0.000   0.000   \n",
       "18      1   0.000   0.000   0.000   0.000   \n",
       "19           None    None    None    None   \n",
       "20           None    None    None    None   \n",
       "21           None    None    None    None   \n",
       "\n",
       "                      filename:lineno(function)  \n",
       "0                    _explainer.py:27(__init__)  \n",
       "1                         method builtins.exec}  \n",
       "2              _general.py:174(safe_isinstance)  \n",
       "3                      method builtins.getattr}  \n",
       "4                    _partition.py:27(__init__)  \n",
       "5                   method builtins.isinstance}  \n",
       "6                    'rsplit' of 'str' objects}  \n",
       "7                          <string>:1(<module>)  \n",
       "8    _linear.py:269(supports_model_with_masker)  \n",
       "9        transformers.py:86(is_transformers_lm)  \n",
       "10                       _model.py:14(__init__)  \n",
       "11     _tree.py:546(supports_model_with_masker)  \n",
       "12                     method builtins.hasattr}  \n",
       "13                    _base.py:1301(isspmatrix)  \n",
       "14  _additive.py:78(supports_model_with_masker)  \n",
       "15                    method builtins.callable}  \n",
       "16     'disable' of '_lsprof.Profiler' objects}  \n",
       "17                  method builtins.issubclass}  \n",
       "18                         method builtins.len}  \n",
       "19                                         None  \n",
       "20                                         None  \n",
       "21                                         None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pstats.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m      \n",
       "\u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfixed_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmain_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0merror_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m            Partition\n",
       "\u001b[0;31mString form:\u001b[0m     shap.explainers.Partition()\n",
       "\u001b[0;31mFile:\u001b[0m            ~/Github/intel-innersource/frameworks.ai.explainable-ai/explainer/explainer/explainers/feature_attributions_explainer/shap/explainers/_partition.py\n",
       "\u001b[0;31mDocstring:\u001b[0m       <no docstring>\n",
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "Uses Shapley values to explain any machine learning model or python function.\n",
       "\n",
       "This is the primary explainer interface for the SHAP library. It takes any combination\n",
       "of a model and masker and returns a callable subclass object that implements\n",
       "the particular estimation algorithm that was chosen.\n",
       "\u001b[0;31mInit docstring:\u001b[0m \n",
       "Uses the Partition SHAP method to explain the output of any function.\n",
       "\n",
       "Partition SHAP computes Shapley values recursively through a hierarchy of features, this\n",
       "hierarchy defines feature coalitions and results in the Owen values from game theory. The\n",
       "PartitionExplainer has two particularly nice properties: 1) PartitionExplainer is\n",
       "model-agnostic but when using a balanced partition tree only has quadradic exact runtime\n",
       "(in term of the number of input features). This is in contrast to the exponential exact\n",
       "runtime of KernelExplainer or SamplingExplainer. 2) PartitionExplainer always assigns to groups of\n",
       "correlated features the credit that set of features would have had if treated as a group. This\n",
       "means if the hierarchical clustering given to PartitionExplainer groups correlated features\n",
       "together, then feature correlations are \"accounted for\" ... in the sense that the total credit assigned\n",
       "to a group of tightly dependent features does net depend on how they behave if their correlation\n",
       "structure was broken during the explanation's perterbation process. Note that for linear models\n",
       "the Owen values that PartitionExplainer returns are the same as the standard non-hierarchical\n",
       "Shapley values.\n",
       "\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "model : function\n",
       "    User supplied function that takes a matrix of samples (# samples x # features) and\n",
       "    computes the output of the model for those samples.\n",
       "\n",
       "masker : function or numpy.array or pandas.DataFrame or tokenizer\n",
       "    The function used to \"mask\" out hidden features of the form `masker(mask, x)`. It takes a\n",
       "    single input sample and a binary mask and returns a matrix of masked samples. These\n",
       "    masked samples will then be evaluated using the model function and the outputs averaged.\n",
       "    As a shortcut for the standard masking using by SHAP you can pass a background data matrix\n",
       "    instead of a function and that matrix will be used for masking. Domain specific masking\n",
       "    functions are available in shap such as shap.maksers.Image for images and shap.maskers.Text\n",
       "    for text.\n",
       "\n",
       "partition_tree : None or function or numpy.array\n",
       "    A hierarchical clustering of the input features represented by a matrix that follows the format\n",
       "    used by scipy.cluster.hierarchy (see the notebooks_html/partition_explainer directory an example).\n",
       "    If this is a function then the function produces a clustering matrix when given a single input\n",
       "    example. If you are using a standard SHAP masker object then you can pass masker.clustering\n",
       "    to use that masker's built-in clustering of the features, or if partition_tree is None then\n",
       "    masker.clustering will be used by default.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "See `Partition explainer examples <https://shap.readthedocs.io/en/latest/api_examples/explainers/Partition.html>`_\n",
       "\u001b[0;31mCall docstring:\u001b[0m \n",
       "Explain the output of the model on the given arguments.\n",
       "        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pinfo explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "sample_text = 'Crossover comfort food with a redemptive twist'\n",
    "Z=masker.clustering(sample_text)\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "dn = dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that the label is true: 41.68%\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForSequenceClassification, BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "model = BartForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
    "\n",
    "# pose sequence as a NLI premise and label (politics) as a hypothesis\n",
    "premise = 'Counterfactuals'\n",
    "hypothesis = 'Machine Learning'\n",
    "\n",
    "# run through model pre-trained on MNLI\n",
    "input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt')\n",
    "logits = model(input_ids)[0]\n",
    "\n",
    "# we throw away \"neutral\" (dim 1) and take the probability of\n",
    "# \"entailment\" (2) as the probability of the label being true \n",
    "entail_contradiction_logits = logits[:,[0,2]]\n",
    "probs = entail_contradiction_logits.softmax(dim=1)\n",
    "true_prob = probs[:,1].item() * 100\n",
    "print(f'Probability that the label is true: {true_prob:0.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/sentence_bert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: Counterfactual \t similarity: 0.2732493281364441\n",
      "label: LayerCAM \t similarity: 0.2626365125179291\n",
      "label: Integrated gradient \t similarity: 0.23581534624099731\n",
      "label: TCAV \t similarity: 0.2109149992465973\n",
      "label: GradCAM \t similarity: 0.1690794974565506\n",
      "label: Smooth gradient \t similarity: 0.1611424684524536\n",
      "label: Partial Dependence Plot \t similarity: 0.15151742100715637\n",
      "label: Contrastive \t similarity: 0.1331045776605606\n",
      "label: ScoreCAM \t similarity: 0.13206973671913147\n",
      "label: Accumulated Local Effects \t similarity: 0.09784331917762756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localdisk/kdkasrav/Github/intel-innersource/frameworks.ai.explainable-ai/explainer/explainer/explainers/feature_attributions_explainer/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import functional as F\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepset/sentence_bert')\n",
    "model = AutoModel.from_pretrained('deepset/sentence_bert')\n",
    "\n",
    "sentence = 'What explainability methods are most often used with the RoBERTa model?'\n",
    "labels = ['Counterfactual', 'Contrastive', 'GradCAM', 'ScoreCAM',\n",
    "          'LayerCAM', 'Smooth gradient', 'Integrated gradient',\n",
    "          'Partial Dependence Plot', 'Accumulated Local Effects',\n",
    "          'TCAV'\n",
    "         ]\n",
    "\n",
    "# run inputs through model and mean-pool over the sequence\n",
    "# dimension to get sequence-level representations\n",
    "inputs = tokenizer.batch_encode_plus([sentence] + labels,\n",
    "                                     return_tensors='pt',\n",
    "                                     pad_to_max_length=True)\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "output = model(input_ids, attention_mask=attention_mask)[0]\n",
    "sentence_rep = output[:1].mean(dim=1)\n",
    "label_reps = output[1:].mean(dim=1)\n",
    "\n",
    "# now find the labels with the highest cosine similarities to\n",
    "# the sentence\n",
    "similarities = F.cosine_similarity(sentence_rep, label_reps)\n",
    "closest = similarities.argsort(descending=True)\n",
    "for ind in closest:\n",
    "    print(f'label: {labels[ind]} \\t similarity: {similarities[ind]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "47de4e6fcdf76d9f7e9823221d58331110ca8a86e4fcaa17b27f269bc08adee8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
