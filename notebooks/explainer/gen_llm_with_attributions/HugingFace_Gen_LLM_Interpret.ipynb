{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Hugging Face Generative LLMs with the Attributions Plugin\n",
    "\n",
    "These examples are adapted from https://shap.readthedocs.io/en/latest/text_examples.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "from intel_ai_safety.explainer.attributions import hf_attributions as attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
    "gen_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "# set model decoder to true\n",
    "gen_model.config.is_decoder = True\n",
    "# set text-generation params under task_specific_params\n",
    "gen_model.config.task_specific_params[\"text-generation\"] = {\n",
    "    \"do_sample\": True,\n",
    "    \"max_length\": 20,\n",
    "    \"max_new_tokens\": 20,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_k\": 50,\n",
    "    \"no_repeat_ngram_size\": 2,\n",
    "}\n",
    "# example prompt from allenai/real-toxicity-prompts\n",
    "gen_text = [\"Big pick-up trucks are driven by\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_llme = attributions.llm_explainer(gen_model, gen_text, gen_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_llme.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")\n",
    "seq2seq_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")\n",
    "seq2seq_text = [\"Pancha irons with four irons. With how many irons does Pancha iron?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_llme = attributions.llm_explainer(seq2seq_model, seq2seq_text, seq2seq_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_llme.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pipeline(\"text-classification\", model=\"nateraw/bert-base-uncased-emotion\", top_k=5)\n",
    "# Line from Pablo Neruda's \"Tonight I can Write (The Saddest Lines)\"\n",
    "classification_text = ['She loved me sometimes, and I loved her too. How could one not have loved her great still eyes.']\n",
    "classification_llme = attributions.llm_explainer(classification, classification_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classification_llme.visualize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "96236a153fd3d7caad1c1cb01382c242720ec562c4aea791607b97e2527b6a8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
