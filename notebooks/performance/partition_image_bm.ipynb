{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7291c7-c12b-4646-85a9-fda16aabc686",
   "metadata": {},
   "source": [
    "# Performance Analysis of The IntelÂ® Explainable AI Tools\n",
    "This notebook consists of timing the duration of Explainer's `PartitionExplainer()` module using a pre-trained TensorFlow ResNet50 on two ImageNet examples. This notebook contains 3 sections:\n",
    "1. Timing _PartitionExplainer_ when Intel optimized flags turn __OFF__ optimizations\n",
    "2. Timing _PartitionExplainer_ when Intel optimized flags turn __ON__ optimizations\n",
    "3. Visualize results comparing both experiments\n",
    "\n",
    "The experiments scale on a parameter called `max_evals` from 64 to 2048 by powers of 2. Originating from the shap library, `max_evals` dictates the amount of forward propagations used in explanation algorithm to get a better estimation of the shap values. Thus, the higher the `max_evals`, the better the shap estimation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d3ddf2",
   "metadata": {},
   "source": [
    "## 1. Execute with Intel Optimizations Off\n",
    "Before importing the major packages, set the three flags (TF_ENABLE_ONEDNN_OPTS, TF_DISABLE_MKL, TF_ENABLE_MKL_NATIVE_FORMAT) to their necessary values to turn oneDNN off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bbf010-4a65-42c8-9365-16f66946392c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the 3 flags to turnoff Intel optimizations\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_DISABLE_MKL'] = '1'\n",
    "os.environ['TF_ENABLE_MKL_NATIVE_FORMAT'] = '0'\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import json\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "from intel_ai_safety.explainer import attributions\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4ef9db",
   "metadata": {},
   "source": [
    "Create the directory where the results will be saved. Current date and time are in the directory name to keep track of runs and to avoid overwriting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649ced09",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "results_dir_name = f'xai_perf_bm_{timestr}'\n",
    "os.mkdir(results_dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316af9e",
   "metadata": {},
   "source": [
    "Here we check if, in fact, oneDNN is set to off. Note that TF versions <2.11 are not guaranteed to report the correct oneDNN status. This cell should output \"oneDNN enabled: False\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cee38e-6b68-495d-a20f-65f14cc72651",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"We are using Tensorflow version\", tf.__version__)\n",
    "major_version = int(tf.__version__.split(\".\")[0])\n",
    "minor_version = int(tf.__version__.split(\".\")[1])\n",
    "if major_version >= 2:\n",
    "    onednn_enabled = 0\n",
    "    if minor_version < 5:\n",
    "        from tensorflow.python import _pywrap_util_port\n",
    "    else:\n",
    "        from tensorflow.python.util import _pywrap_util_port\n",
    "        onednn_enabled = int(os.environ.get('TF_ENABLE_ONEDNN_OPTS', '0'))\n",
    "    on_onednn = _pywrap_util_port.IsMklEnabled() or (onednn_enabled == 1)\n",
    "else:\n",
    "    on_onednn = tf.pywrap_tensorflow.IsMklEnabled()\n",
    "\n",
    "print(\"oneDNN enabled:\", on_onednn)\n",
    "\n",
    "# Don't use GPUs if there are any\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db54367",
   "metadata": {},
   "source": [
    "Now we can load the pre-trained ResNet50 and ImageNet dataset where we will only use 2 images for the experiment. We also load the ImageNet classnames needed for `PartitionExplainer()` instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643daec7-7c94-4463-926e-fca635bc8af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load pre-trained model and choose two images to explain\n",
    "print('load model')\n",
    "model = ResNet50(weights='imagenet')\n",
    "f = lambda x: model(preprocess_input(x.copy()))\n",
    "\n",
    "\n",
    "X, y = shap.datasets.imagenet50()\n",
    "\n",
    "# only select 2 images from the dataset\n",
    "X_bm = X[1:3]\n",
    "\n",
    "# load the ImageNet class names as a vectorized mapping function from ids to names\n",
    "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "with open(shap.datasets.cache(url)) as file:\n",
    "    class_names = [v[1] for v in json.load(file).values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676081eb",
   "metadata": {},
   "source": [
    "Finally we can now run the experiment and record the computation times when oneDNN is off. Every max_eval is iteration is executed 5 times to account for CPU processing variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate the PartitionExplainer object to be used in the benchmark\n",
    "pe = attributions.PartitionExplainer('image', f, class_names, X_bm[0].shape)\n",
    "\n",
    "#run the first iteration to remove warm-up time\n",
    "pe.run_explainer(X_bm)\n",
    "\n",
    "onednn_off_times = {64: [],\n",
    "         128: [],\n",
    "         256: [],\n",
    "         512: [],\n",
    "         1024: [],\n",
    "         2048: [],\n",
    "        }\n",
    "\n",
    "for max_evals in [64, 128, 256, 512, 1024, 2048]:\n",
    "    print(max_evals)\n",
    "    for _ in range(5):\n",
    "        print(_)\n",
    "        pe.run_explainer(X_bm, max_evals=max_evals)\n",
    "        onednn_off_times[max_evals].append(pe.shap_values.compute_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24340ae0",
   "metadata": {},
   "source": [
    "Save the results in the results directory created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb52db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(results_dir_name, f'oneDNN_off_times.pkl'), 'wb') as f:\n",
    "    pickle.dump(onednn_off_times, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3dfaed",
   "metadata": {},
   "source": [
    "# 2. Execute with Intel Optimizations On\n",
    "Before importing the major packages, set the three flags (TF_ENABLE_ONEDNN_OPTS, TF_DISABLE_MKL, TF_ENABLE_MKL_NATIVE_FORMAT) to their necessary values to turn oneDNN on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2da66a-1d6d-47c5-a6df-cf5e9e1e65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-import libraries after setting flag to turn on optimizations\n",
    "import os\n",
    "\n",
    "# Set the 3 flags to turnoff Intel optimizations\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
    "os.environ['TF_DISABLE_MKL'] = '0'\n",
    "os.environ['TF_ENABLE_MKL_NATIVE_FORMAT'] = '1'\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import json\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "from intel_ai_safety.explainer.attributions import attributions\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9014b3",
   "metadata": {},
   "source": [
    "Here we check if, in fact, oneDNN is set to on. Note that TF versions <2.11 are not guaranteed to report the correct oneDNN status. This cell should output \"oneDNN enabled: True\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c463421-3155-437f-a3ee-6278fe5c9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"We are using Tensorflow version\", tf.__version__)\n",
    "major_version = int(tf.__version__.split(\".\")[0])\n",
    "minor_version = int(tf.__version__.split(\".\")[1])\n",
    "if major_version >= 2:\n",
    "    onednn_enabled = 0\n",
    "    if minor_version < 5:\n",
    "        from tensorflow.python import _pywrap_util_port\n",
    "    else:\n",
    "        from tensorflow.python.util import _pywrap_util_port\n",
    "        onednn_enabled = int(os.environ.get('TF_ENABLE_ONEDNN_OPTS', '0'))\n",
    "    on_onednn = _pywrap_util_port.IsMklEnabled() or (onednn_enabled == 1)\n",
    "else:\n",
    "    on_onednn = tf.pywrap_tensorflow.IsMklEnabled()\n",
    "\n",
    "print(\"oneDNN enabled:\", on_onednn)\n",
    "\n",
    "# Don't use GPUs if there are any \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f17c59d",
   "metadata": {},
   "source": [
    "Now we must re-load the pre-trained ResNet50 to reset model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1255dad6-6e84-4033-8449-edbfbe3655f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload pre-trained\n",
    "print('load model')\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# redefine function - will error if not redefined\n",
    "f = lambda x: model(preprocess_input(x.copy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d27fd0",
   "metadata": {},
   "source": [
    "Finally we can now run the experiment and record the computation times when oneDNN is on. Every max_eval is iteration is executed 5 times to account for CPU processing variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb1e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-instatiate PartitionExplainer object\n",
    "pe = attributions.PartitionExplainer('image', f, class_names, X_bm[0].shape)\n",
    "#run the first iteration to remove warm-up time\n",
    "pe.run_explainer(X_bm)\n",
    "\n",
    "onednn_on_times = {64: [],\n",
    "         128: [],\n",
    "         256: [],\n",
    "         512: [],\n",
    "         1024: [],\n",
    "         2048: [],\n",
    "        }\n",
    "# run the benchmark\n",
    "for max_evals in [64, 128, 256, 512, 1024, 2048]:\n",
    "    print(max_evals)\n",
    "    for _ in range(5):\n",
    "        print(_)\n",
    "        pe.run_explainer(X_bm, max_evals=max_evals)\n",
    "        onednn_on_times[max_evals].append(pe.shap_values.compute_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137cb7ff",
   "metadata": {},
   "source": [
    "Save the results in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c5dbc-e2fb-47bc-901c-8732b0c95a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(results_dir_name, f'oneDNN_on_times.pkl'), 'wb') as f:\n",
    "    pickle.dump(onednn_on_times, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b85d2",
   "metadata": {},
   "source": [
    "## 3. Visualize results comparing both benchmarks\n",
    "First we will aggregate the results of the two experiments into pandas DataFrames that contain the experiment counts, means, stds, confidence intervals, and upper and lower confidence interval marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a065ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def group_dict_to_df(results_dict):\n",
    "    '''\n",
    "    Converts dictionary of benchmark times to a pd.DataFrame that aggregates \n",
    "    benchmark times to counts, means, stds, confidence interval, upper and\n",
    "    lower confidence intervals\n",
    "    '''\n",
    "    df = pd.DataFrame.from_dict(results_dict)\n",
    "    df = df.agg(['mean', 'std', 'count']).T\n",
    "    # Calculate a confidence interval as well.\n",
    "    df['ci'] = 1.96 * df['std'] / np.sqrt(df['count'])\n",
    "    df['ci_lower'] = df['mean'] - df['ci']\n",
    "    df['ci_upper'] = df['mean'] + df['ci']\n",
    "    return df\n",
    "\n",
    "\n",
    "# convert bm dictionaries to aggregated DataFrames\n",
    "onednn_on_times_df = group_dict_to_df(onednn_on_times)\n",
    "onednn_off_times_df = group_dict_to_df(onednn_off_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e19e50",
   "metadata": {},
   "source": [
    "Now we will save the DataFrames as csv's in the same directory we saved the raw results. Let's also display the DataFrames to confirm they are values that we would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dfs to csvs\n",
    "onednn_on_times_df.to_csv(os.path.join(results_dir_name, 'oneDNN_on_times_aggregated.csv'))\n",
    "onednn_off_times_df.to_csv(os.path.join(results_dir_name, 'oneDNN_off_times_aggregated.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b1474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "onednn_off_times_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4fecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "onednn_on_times_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bfd4d",
   "metadata": {},
   "source": [
    "Now we can line plot both experiments (along with their confidence intervals) with respect to max_evals to see how they compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot benchmark averages against eachother with confidence interval\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "x = onednn_on_times_df.index\n",
    "ax.plot(x, onednn_on_times_df['mean'],  marker='.', label='Intel OneDNN Flags')\n",
    "ax.fill_between(\n",
    "    x, onednn_on_times_df['ci_lower'], onednn_on_times_df['ci_upper'], color='b', alpha=.1)\n",
    "\n",
    "ax.plot(x, onednn_off_times_df['mean'], color='r', marker='d', label='No Intel Flags')\n",
    "ax.fill_between(\n",
    "    x, onednn_off_times_df['ci_lower'], onednn_off_times_df['ci_upper'], color='r', alpha=.1)\n",
    "\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.set_xlim(xmin=64, xmax=2048)\n",
    "ax.set_xticks(x)\n",
    "ax.set_ylabel('Time (s)')\n",
    "ax.set_xlabel('Max Evaluations')\n",
    "ax.set_title('Avg Compute Time by Max Evaluations (n=5)')\n",
    "ax.grid(axis='y')\n",
    "ax.legend()\n",
    "\n",
    "fig.autofmt_xdate(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09a004",
   "metadata": {},
   "source": [
    "Let's also bar plot the percent decrease in compute time from oneDNN off to oneDNN on to see where which max_evals iteration resulted the greatest optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a6cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "for on, off in zip(onednn_on_times_df['mean'], onednn_off_times_df['mean']):\n",
    "    diffs.append(((on - off)/off)*100)\n",
    "\n",
    "# compare reduction in time between stock and Intel optimizations\n",
    "diffs_series = pd.Series(np.array(diffs)*-1)\n",
    "plt.figure(figsize=(10,6))\n",
    "fig = diffs_series.plot(kind='bar')\n",
    "fig.set_xticklabels(['64', '128', '256', '512', '1028', '2048'])\n",
    "fig.bar_label(fig.containers[0], label_type='edge')\n",
    "fig.set_title('Stock VS Intel Flags Percent Decrease in Computation Time')\n",
    "fig.set_xlabel('Max Evaluations')\n",
    "fig.set_ylabel('% Decrease')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
