<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Metrics &mdash; Intel® Explainable AI Tools 0.5.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/design-tabs.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model Card Generator" href="../model_card_gen/index.html" />
    <link rel="prev" title="CAM (Class Activation Mapping)" href="cam.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Intel® Explainable AI Tools
          </a>
              <div class="version">
                0.5.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Explainer</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="attributions.html">Feature Attributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="cam.html">CAM (Class Activation Mapping)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Metrics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../model_card_gen/index.html">Model Card Generator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legal.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/IntelAI/intel-xai-tools">GitHub Repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Intel® Explainable AI Tools</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Explainer</a></li>
      <li class="breadcrumb-item active">Metrics</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/explainer/metrics.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="metrics">
<span id="id1"></span><h1>Metrics<a class="headerlink" href="#metrics" title="Permalink to this heading"></a></h1>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">explainer</span> <span class="kn">import</span> <span class="n">metrics</span>
</pre></div>
</div>
<p>Several base metrics are provided for ML/DL classification models. These metrics cover model execution and performance and orient the data scientist to where there is potential for classification bias.</p>
<section id="algorithms">
<h2>Algorithms<a class="headerlink" href="#algorithms" title="Permalink to this heading"></a></h2>
<p>Provided with a classfication model’s predictions and their corresponding ground truths, staple performance metrics can be calculated to determine prediction behaviors in the real world. These functions leverage scikit-learn and plotly (eventually) to calculate and visualize said metrics, respectively.</p>
</section>
<section id="environment">
<h2>Environment<a class="headerlink" href="#environment" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Jupyter Notebooks</p></li>
</ul>
</section>
<section id="id2">
<h2>Metrics<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Performance metrics</p>
<ul>
<li><p>Confusion Matrix</p></li>
<li><p>Performance Plots</p></li>
</ul>
</li>
<li><p>Execution metrics</p>
<ul>
<li><p>Python profiler</p></li>
</ul>
</li>
</ul>
</section>
<section id="toolkits">
<h2>Toolkits<a class="headerlink" href="#toolkits" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Scikit-learn</p></li>
<li><p>Plotly</p></li>
<li><p>Python Profilers</p></li>
</ul>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading"></a></h2>
<p><a class="reference external" href="https://github.com/scikit-learn/scikit-learn">Scikit-learn</a><br />
<a class="reference external" href="https://github.com/plotly">Plotly</a><br />
<a class="reference external" href="https://github.com/python/cpython/blob/main/Lib/cProfile.py">Python Profiler</a></p>
</section>
<section id="module-explainer.metrics.metrics">
<span id="api-refrence"></span><h2>API Refrence<a class="headerlink" href="#module-explainer.metrics.metrics" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="explainer.metrics.metrics.ConfusionMatrix">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">explainer.metrics.metrics.</span></span><span class="sig-name descname"><span class="pre">ConfusionMatrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">groundtruth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/explainer/metrics/metrics.html#ConfusionMatrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#explainer.metrics.metrics.ConfusionMatrix" title="Permalink to this definition"></a></dt>
<dd><p>Confusion matrix object that holds the accuracy for each classification type in Cij, where
C is the confusion matrix, i is a ground truth label and j is the model’s label prediction.
Confusion matrices are tool to help initially diagnose how well the model performs across
all class labels. Checking these accuracies on unseen test data (real-world data) is a
first step in identifying possible sample bias.</p>
<p>This class supports both binary and multi-class classification. Currently, the accuracies
are normalized across each ground truth (row).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>truth</strong> (<em>ground</em>) – 1-d or 2-d array (if one-hot-encoded) of the integer ground truth labels</p></li>
<li><p><strong>predictions</strong> – 2-d array (n_samples, n_classes) of the one-hot-encoded, predicted probabilities
that align with the ground truth array</p></li>
<li><p><strong>labels</strong> – 1-d array of strings that index the label names to the one-hot encodings</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.ConfusionMatrix.y_gt">
<span class="sig-name descname"><span class="pre">y_gt</span></span><a class="headerlink" href="#explainer.metrics.metrics.ConfusionMatrix.y_gt" title="Permalink to this definition"></a></dt>
<dd><p>1-d array of integer ground truth labels</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.ConfusionMatrix.y_pred">
<span class="sig-name descname"><span class="pre">y_pred</span></span><a class="headerlink" href="#explainer.metrics.metrics.ConfusionMatrix.y_pred" title="Permalink to this definition"></a></dt>
<dd><p>1-d array of integer class prediction labels</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.ConfusionMatrix.labels">
<span class="sig-name descname"><span class="pre">labels</span></span><a class="headerlink" href="#explainer.metrics.metrics.ConfusionMatrix.labels" title="Permalink to this definition"></a></dt>
<dd><p>1-d array of label names (strings) corresponding to the integer label indexes</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.ConfusionMatrix.arr">
<span class="sig-name descname"><span class="pre">arr</span></span><a class="headerlink" href="#explainer.metrics.metrics.ConfusionMatrix.arr" title="Permalink to this definition"></a></dt>
<dd><p>2-d array of float64s holding the confusion matrix</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.ConfusionMatrix.df">
<span class="sig-name descname"><span class="pre">df</span></span><a class="headerlink" href="#explainer.metrics.metrics.ConfusionMatrix.df" title="Permalink to this definition"></a></dt>
<dd><p>Pandas DataFrame holding the confusion matrix with the associated label names
for the indexes and column names</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.ConfusionMatrix.report">
<span class="sig-name descname"><span class="pre">report</span></span><a class="headerlink" href="#explainer.metrics.metrics.ConfusionMatrix.report" title="Permalink to this definition"></a></dt>
<dd><p>A string summary of performances for all classes including precision, recall, f1-score,
and support.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="explainer.metrics.metrics.ConfusionMatrix.visualize">
<span class="sig-name descname"><span class="pre">visualize</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/explainer/metrics/metrics.html#ConfusionMatrix.visualize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#explainer.metrics.metrics.ConfusionMatrix.visualize" title="Permalink to this definition"></a></dt>
<dd><p>Plot the confusion matrix on a heatmap</p>
</dd></dl>

<dl class="simple">
<dt>Reference:</dt><dd><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="explainer.metrics.metrics.PStats">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">explainer.metrics.metrics.</span></span><span class="sig-name descname"><span class="pre">PStats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">command</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/explainer/metrics/metrics.html#PStats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#explainer.metrics.metrics.PStats" title="Permalink to this definition"></a></dt>
<dd><p>Executes cProfile.run and saves the results in the PStats class as panda DataFrames.
Two DataFrames are stored - A summary and a report which call PStats.summary and PStats.report respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>command</strong> (<em>string</em>) – the command to be analyzed</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.PStats.profile">
<span class="sig-name descname"><span class="pre">profile</span></span><a class="headerlink" href="#explainer.metrics.metrics.PStats.profile" title="Permalink to this definition"></a></dt>
<dd><p>tokenized results of cProfile.run() on the command in a list of strings</p>
</dd></dl>

<dl class="simple">
<dt>Reference:</dt><dd><p><a class="reference external" href="https://docs.python.org/3/library/profile.html">https://docs.python.org/3/library/profile.html</a></p>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="explainer.metrics.metrics.PStats.report">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">report</span></span><a class="headerlink" href="#explainer.metrics.metrics.PStats.report" title="Permalink to this definition"></a></dt>
<dd><p>Pandas DataFrame in-depth report of the duration of each call</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="explainer.metrics.metrics.PStats.summary">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">summary</span></span><a class="headerlink" href="#explainer.metrics.metrics.PStats.summary" title="Permalink to this definition"></a></dt>
<dd><p>Pandas DataFrame summarizing duration of each function</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="explainer.metrics.metrics.Plotter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">explainer.metrics.metrics.</span></span><span class="sig-name descname"><span class="pre">Plotter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">groundtruth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/explainer/metrics/metrics.html#Plotter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#explainer.metrics.metrics.Plotter" title="Permalink to this definition"></a></dt>
<dd><p>Plotter object that calculates and holds the necessary values for various plots commonly used in
post-training analysis on test data. In particular, these plots utilize thesholding the predicted
probabilities in order to quantify the skill of the model. They provide behavior of the classification
rates dependent upon these probability thresholds and are useful in diagnosing dataset imbalance issues.</p>
<p>This class accepts both binary and multi-class classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>truth</strong> (<em>ground</em>) – 1-d or 2-d array (if one-hot-encoded) of the integer ground truth labels</p></li>
<li><p><strong>predictions</strong> – 2-d array (n_samples, n_classes) of the one-hot-encoded, predicted probabilities
that align with the ground truth array</p></li>
<li><p><strong>labels</strong> – 1-d array of strings that index the label names to the one-hot encodings</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.Plotter.y_gt">
<span class="sig-name descname"><span class="pre">y_gt</span></span><a class="headerlink" href="#explainer.metrics.metrics.Plotter.y_gt" title="Permalink to this definition"></a></dt>
<dd><p>2-d array of one-hot-encoded integer ground truth labels</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.Plotter.y_pred">
<span class="sig-name descname"><span class="pre">y_pred</span></span><a class="headerlink" href="#explainer.metrics.metrics.Plotter.y_pred" title="Permalink to this definition"></a></dt>
<dd><p>2-d array of class predicted probabilities</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.Plotter.labels">
<span class="sig-name descname"><span class="pre">labels</span></span><a class="headerlink" href="#explainer.metrics.metrics.Plotter.labels" title="Permalink to this definition"></a></dt>
<dd><p>1-d array of label names (strings) corresponding to the integer label indexes</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.Plotter.arr">
<span class="sig-name descname"><span class="pre">arr</span></span><a class="headerlink" href="#explainer.metrics.metrics.Plotter.arr" title="Permalink to this definition"></a></dt>
<dd><p>2-d array of float64s holding the confusion matrix</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.Plotter.precision">
<span class="sig-name descname"><span class="pre">precision</span></span><a class="headerlink" href="#explainer.metrics.metrics.Plotter.precision" title="Permalink to this definition"></a></dt>
<dd><p>Python dict that holds a 1-d array of precisions at every threshold step for each class label
where each key corresponds to the class label index. Used for PR curve</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.Plotter.recall">
<span class="sig-name descname"><span class="pre">recall</span></span><a class="headerlink" href="#explainer.metrics.metrics.Plotter.recall" title="Permalink to this definition"></a></dt>
<dd><p>Python dict that holds a 1-d array of recalls at every threshold step for each class label
where each key corresponds to the class label index. Used for PR curve</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.Plotter.tpr">
<span class="sig-name descname"><span class="pre">tpr</span></span><a class="headerlink" href="#explainer.metrics.metrics.Plotter.tpr" title="Permalink to this definition"></a></dt>
<dd><p>Python dict that holds a 1-d array of true-positive rates at every threshold step for each class label
where each key corresponds to the class label index. Used for PR curve</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="explainer.metrics.metrics.Plotter.fpr">
<span class="sig-name descname"><span class="pre">fpr</span></span><a class="headerlink" href="#explainer.metrics.metrics.Plotter.fpr" title="Permalink to this definition"></a></dt>
<dd><p>Python dict that holds a 1-d array of false-positive rates at every threshold step for each class label
where each key corresponds to the class label index. Used for PR curve</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="explainer.metrics.metrics.Plotter.pr_curve">
<span class="sig-name descname"><span class="pre">pr_curve</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/explainer/metrics/metrics.html#Plotter.pr_curve"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#explainer.metrics.metrics.Plotter.pr_curve" title="Permalink to this definition"></a></dt>
<dd><p>plots the precision recall curve for all classes present in labels</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="explainer.metrics.metrics.Plotter.roc_curve">
<span class="sig-name descname"><span class="pre">roc_curve</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/explainer/metrics/metrics.html#Plotter.roc_curve"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#explainer.metrics.metrics.Plotter.roc_curve" title="Permalink to this definition"></a></dt>
<dd><p>plots the receiver-operator characteristics curve for all classes present in labels</p>
</dd></dl>

<dl class="simple">
<dt>Reference:</dt><dd><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html</a>
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html</a></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="id0">
<span class="sig-name descname"><span class="pre">pr_curve</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/explainer/metrics/metrics.html#Plotter.pr_curve"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id0" title="Permalink to this definition"></a></dt>
<dd><p>Plot the Precision-Recall Curve</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id1">
<span class="sig-name descname"><span class="pre">roc_curve</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/explainer/metrics/metrics.html#Plotter.roc_curve"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id1" title="Permalink to this definition"></a></dt>
<dd><p>Plot the receiver operating charactersitic curve</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="explainer.metrics.metrics.confusion_matrix">
<span class="sig-prename descclassname"><span class="pre">explainer.metrics.metrics.</span></span><span class="sig-name descname"><span class="pre">confusion_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">groundtruth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/explainer/metrics/metrics.html#confusion_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#explainer.metrics.metrics.confusion_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Generates instantiation of a ConfusionMatrix object that holds necessary information
and metrics from the confusion matrix</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>groundtruth</strong> – 2-d array (n_samples, n_classes) of the ground truth, integer one-hot-encoded,
correct target values that correspond to the examples used in testing</p></li>
<li><p><strong>predictions</strong> – 2-d array (n_samples, n_classes) of the one-hot-encoded, predicted probabilities
that align with the groundtruth array</p></li>
<li><p><strong>labels</strong> – 1-d array of strings that index the label names to the one-hot encodings</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ConfusionMatrix object instantiation</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#explainer.metrics.metrics.ConfusionMatrix" title="explainer.metrics.metrics.ConfusionMatrix">ConfusionMatrix</a></p>
</dd>
</dl>
<dl class="simple">
<dt>Reference:</dt><dd><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">explainer</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cm</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">label_names</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">df</span><span class="p">)</span>
<span class="go">       cat  dog  horse</span>
<span class="go">cat    0.5  0.5    0.0</span>
<span class="go">dog    0.0  1.0    0.0</span>
<span class="go">horse  0.0  0.0    1.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="explainer.metrics.metrics.plot">
<span class="sig-prename descclassname"><span class="pre">explainer.metrics.metrics.</span></span><span class="sig-name descname"><span class="pre">plot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">groundtruth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/explainer/metrics/metrics.html#plot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#explainer.metrics.metrics.plot" title="Permalink to this definition"></a></dt>
<dd><p>Generates instantiation of a Plotter object that holds necessary information
to plot the precision-recall curve and receiver-operator characteristics curve</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>groundtruth</strong> – 2-d array (n_samples, n_classes) of the ground truth, integer one-hot-encoded, correct target values
that correspond to the examples used in testing</p></li>
<li><p><strong>predictions</strong> – 2-d array (n_samples, n_classes) of the one-hot-encoded, predicted probabilities
that align with the groundtruth array</p></li>
<li><p><strong>labels</strong> – 1-d array of strings that index the label names to the one-hot encodings</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Plotter object instantiation</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#explainer.metrics.metrics.Plotter" title="explainer.metrics.metrics.Plotter">Plotter</a></p>
</dd>
</dl>
<dl class="simple">
<dt>Reference:</dt><dd><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">.002</span><span class="p">,</span> <span class="mf">.09</span><span class="p">,</span> <span class="mf">.89</span><span class="p">],</span> <span class="p">[</span><span class="mf">.01</span><span class="p">,</span> <span class="mf">.7</span><span class="p">,</span> <span class="mf">.29</span><span class="p">],</span> <span class="p">[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.67</span><span class="p">,</span> <span class="mf">.03</span><span class="p">],</span> <span class="p">[</span><span class="mf">.55</span><span class="p">,</span> <span class="mf">.4</span><span class="p">,</span> <span class="mf">.05</span><span class="p">],</span> <span class="p">[</span><span class="mf">.03</span><span class="p">,</span> <span class="mf">.86</span><span class="p">,</span> <span class="mf">.11</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">explainer</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plotter</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">label_names</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plotter</span><span class="o">.</span><span class="n">recall</span>
<span class="go">{0: array([1. , 1. , 0.5, 0.5, 0.5, 0. ]), 1: array([1. , 1. , 1. , 0.5, 0.5, 0. ]), 2: array([1., 1., 1., 1., 1., 0.])}</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="explainer.metrics.metrics.pstats">
<span class="sig-prename descclassname"><span class="pre">explainer.metrics.metrics.</span></span><span class="sig-name descname"><span class="pre">pstats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">command</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/explainer/metrics/metrics.html#pstats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#explainer.metrics.metrics.pstats" title="Permalink to this definition"></a></dt>
<dd><p>Executes cProfile.run and saves the results in the PStats class as panda DataFrames.
Two DataFrames are stored - A summary and a report which call PStats.summary and PStats.report respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>command</strong> – command to run</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>this class provides summary and report methods to display the DataFrames</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#explainer.metrics.metrics.PStats" title="explainer.metrics.metrics.PStats">PStats</a></p>
</dd>
</dl>
<dl class="simple">
<dt>Reference:</dt><dd><p><a class="reference external" href="https://docs.python.org/3/library/profile.html">https://docs.python.org/3/library/profile.html</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">random</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">explainer</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">pstats</span><span class="p">(</span><span class="s1">&#39;[i**2 for i in range(100000)]&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">report</span> 
<span class="go">      ncalls tottime percall cumtime percall                 filename:lineno(function)</span>
<span class="go">0      1   0.025   0.025   0.025   0.025                    &lt;string&gt;:1(&lt;listcomp&gt;)</span>
<span class="go">1      1   0.001   0.001   0.026   0.026                      &lt;string&gt;:1(&lt;module&gt;)</span>
<span class="go">2      1   0.000   0.000   0.027   0.027                     method builtins.exec}</span>
<span class="go">3      1   0.000   0.000   0.000   0.000  &#39;disable&#39; of &#39;_lsprof.Profiler&#39; objects}</span>
<span class="go">4           None    None    None    None                                      None</span>
<span class="go">5           None    None    None    None                                      None</span>
<span class="go">6           None    None    None    None                                      None</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cam.html" class="btn btn-neutral float-left" title="CAM (Class Activation Mapping)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../model_card_gen/index.html" class="btn btn-neutral float-right" title="Model Card Generator" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Intel.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>