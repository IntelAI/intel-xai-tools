---
@article{bennetot2021practical,
  title={A Practical Tutorial on Explainable AI Techniques},
  author={Bennetot, Adrien and Donadello, Ivan and Qadi, Ayoub El and Dragoni, Mauro and Frossard, Thomas and Wagner, Benedikt and Saranti, Anna and Tulli, Silvia and Trocan, Maria and Chatila, Raja and others},
  journal={arXiv preprint arXiv:2111.14260},
  year={2021}
}
@misc{logictensornetworks,
    title={Logic Tensor Networks (LTN)},
    author={Logic Tensor Networks (LTN)},
    booktitle={GitHub},
    year={2022}
}
@inproceedings{mothilal2020explaining,
  title={Explaining machine learning classifiers through diverse counterfactual explanations},
  author={Mothilal, Ramaravind K and Sharma, Amit and Tan, Chenhao},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={607--617},
  year={2020}
}
@article{chou2022counterfactuals,
  title={Counterfactuals and causability in explainable artificial intelligence: Theory, algorithms, and applications},
  author={Chou, Yu-Liang and Moreira, Catarina and Bruza, Peter and Ouyang, Chun and Jorge, Joaquim},
  journal={Information Fusion},
  volume={81},
  pages={59--83},
  year={2022},
  publisher={Elsevier}
}
@article{YANG202229,
title = {Unbox the black-box for the medical explainable AI via multi-modal and multi-centre data fusion: A mini-review, two showcases and beyond},
journal = {Information Fusion},
volume = {77},
pages = {29-52},
year = {2022},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2021.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S1566253521001597},
author = {Guang Yang and Qinghao Ye and Jun Xia},
keywords = {Explainable AI, Information fusion, Multi-domain information fusion, Weakly supervised learning, Medical image analysis},
abstract = {Explainable Artificial Intelligence (XAI) is an emerging research topic of machine learning aimed at unboxing how AI systemsâ€™ black-box choices are made. This research field inspects the measures and models involved in decision-making and seeks solutions to explain them explicitly. Many of the machine learning algorithms cannot manifest how and why a decision has been cast. This is particularly true of the most popular deep neural network approaches currently in use. Consequently, our confidence in AI systems can be hindered by the lack of explainability in these black-box models. The XAI becomes more and more crucial for deep learning powered applications, especially for medical and healthcare studies, although in general these deep neural networks can return an arresting dividend in performance. The insufficient explainability and transparency in most existing AI systems can be one of the major reasons that successful implementation and integration of AI tools into routine clinical practice are uncommon. In this study, we first surveyed the current progress of XAI and in particular its advances in healthcare applications. We then introduced our solutions for XAI leveraging multi-modal and multi-centre data fusion, and subsequently validated in two showcases following real clinical scenarios. Comprehensive quantitative and qualitative analyses can prove the efficacy of our proposed XAI solutions, from which we can envisage successful applications in a broader range of clinical questions.}
}
---
