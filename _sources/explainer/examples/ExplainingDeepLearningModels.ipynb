{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Deep Learning Models\n",
    "## CHAPTER 07 - *Practical exposure of using SHAP in ML*\n",
    "\n",
    "From **Applied Machine Learning Explainability Techniques** by [**Aditya Bhattacharya**](https://www.linkedin.com/in/aditya-bhattacharya-b59155b6/), published by **Packt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "The goal of this notebook is to explore model explainability of deep learning image classification models using SHAP. Please check out *Chapter 7 - Practical exposure of using SHAP in ML* for other interesting approaches of using SHAP in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** optimized **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intel-tensorflow==2.9.1\n",
    "# intel-python==3.9.12,  intel-tensorflow==2.9.1, numba-dpex==0.18.1, dpctl==0.13.0\n",
    "# shap @ git+https://github.com/slundberg/shap@v0.41.0\n",
    "from explainer.explainers import feature_attributions_explainer, metrics_explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** non-optimized **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# intel-python==3.9.12, tensorflow==2.9.1\n",
    "from explainer.explainers import shap_explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as c_map\n",
    "from IPython.display import Image, display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import json\n",
    "\n",
    "import shap\n",
    "print(f\"Tensorflow version {tf.__version__} Shap version {shap.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1.keras.backend as K\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "print('Disable Eager Execution for SHAP to work')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gradient Explainers in SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose an image from SHAP datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shap.datasets.imagenet50(resolution=224)\n",
    "inference_image = X[[46]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19(weights='imagenet') # Let's use VGG19 as our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient explainer helps to map the gradient flow of intermediate layers of a Deep Learning model to explain the working of the model. Let's choose layer 10 for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 10 # Let's analyze the 10th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain how the input to the 10th layer of the model explains the top two classes\n",
    "def map2layer(x, layer):\n",
    "    '''\n",
    "    Source : https://github.com/slundberg/shap\n",
    "    '''\n",
    "    feed_dict = dict(zip([model.layers[0].input], [preprocess_input(x.copy())]))\n",
    "    return K.get_session().run(model.layers[layer].input, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** optimized **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pstats = metrics_explainer['pstats']\n",
    "??pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intel-python,  intel-tensorflow, numba-dpex, dpctl\n",
    "model_input = (model.layers[layer_num].input, model.layers[-1].output)\n",
    "pstats = metrics_explainer['pstats']('explainer = shap.GradientExplainer(model_input, map2layer(X, layer_num), local_smoothing=0)')\n",
    "pstats.summary\n",
    "pstats.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false --no-raise-error\n",
    "# intel-python,  intel-tensorflow, numba-dpex, dpctl\n",
    "# pstats = metrics_explainer['pstats']('shap_values, ind = explainer.shap_values(map2layer(inference_image, layer_num), ranked_outputs=4)')\n",
    "# pstats.summary\n",
    "# pstats.report\n",
    "shap_values, ind = explainer.shap_values(map2layer(inference_image, layer_num), ranked_outputs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ImageNet class names\n",
    "def load_imagenet_classes(url, ind):\n",
    "    from urllib.request import urlopen\n",
    "    import json\n",
    "    import numpy as np\n",
    "    response = urlopen(url)\n",
    "    json_data = response.read().decode('utf-8')\n",
    "    classes = json.loads(json_data)    \n",
    "    class_names = np.vectorize(lambda x: classes[str(x)][1])(ind)\n",
    "    return classes, class_names\n",
    "\n",
    "url='https://raw.githubusercontent.com/WZMIAOMIAO/deep-learning-for-image-processing/master/pytorch_classification/mini_imagenet/imagenet_class_index.json'\n",
    "imagenet_classes, class_names = load_imagenet_classes(url, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the explanations\n",
    "shap.image_plot(shap_values, inference_image, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above image, we can clearly see that based on the regions highlighted by the SHAP values how the model prediction is changing. When the model predicted the outcome as desktop computer, the region around the computer monitor keyboard and the desk got highlighted. Please observe that the man in the picture did not get highlighted. That is why the model did not predict the outcome as a man or human-being. Similarly, if you see that other possible predictions of desk monitor and screen, accordingly the different regions of the images are highlighted. This does provide a good explanation for the model outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Deep Explainers in SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use Deep Explainers in SHAP for Deep Learning models. But let's train a model from scratch in this example, instead of using pre-trained model architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading the modules for this new section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# load package\n",
    "import shap\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "x_train = x_train.reshape(50000, 32, 32, 3).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 32, 32, 3).astype(\"float32\") / 255\n",
    "y_train = y_train.reshape(50000,)\n",
    "y_test = y_test.reshape(10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# define the model architecture\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "      loss= 'sparse_categorical_crossentropy',\n",
    "      optimizer= 'Adam',\n",
    "      metrics=['sparse_categorical_accuracy']\n",
    "  )\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the model scores, we can see that our model has a good training accuracy, but not so good validation accuracy, indicating that the model is clearly over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "model.save('models/convo_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "reconstructed_model = keras.models.load_model(\"models/convo_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Classes in CIFAR-10 data\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Source : https://towardsdatascience.com/deep-learning-model-interpretation-using-shap-a21786e91d16\n",
    "# Fetching an image for each of CIFAR-10 class\n",
    "images_dict = dict()\n",
    "for ind, label in enumerate(y_train):\n",
    "    if len(images_dict)==10:\n",
    "        break\n",
    "    if label not in images_dict.keys():\n",
    "        images_dict[label] = x_train[ind].reshape((32, 32,3))\n",
    "images_dict = dict(sorted(images_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Fetching an image for each of CIFAR-10 class for test set\n",
    "x_test_dict = dict()\n",
    "for ind, label in enumerate(y_test):\n",
    "    if len(x_test_dict)==10:\n",
    "        break\n",
    "    if label not in x_test_dict.keys():\n",
    "        x_test_dict[label] = x_test[ind]\n",
    "\n",
    "# sorting\n",
    "sample_x_test = [x_test_dict[i] for i in sorted(x_test_dict)]\n",
    "sample_x_test = np.asarray(sample_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Checking the predictions\n",
    "predictions = model.predict(sample_x_test)\n",
    "predicted_class = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "confusionmatrix = metrics_explainer['confusionmatrix']\n",
    "confusionmatrix.__doc__\n",
    "#confusionmatrix(sample_x_text, predictions, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Source : https://towardsdatascience.com/deep-learning-model-interpretation-using-shap-a21786e91d16\n",
    "# plot actual and predicted class\n",
    "def plot_actual_predicted(images, pred_classes):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(16, 6))\n",
    "    fig.tight_layout()\n",
    "    axes = axes.flatten()\n",
    "    ax = axes[0]\n",
    "    # plot image\n",
    "    for k,v in images.items():\n",
    "        ax = axes[k]\n",
    "        ax.imshow(cv2.resize(v, (512,512)), cmap=plt.cm.binary)\n",
    "        ax.set_title(f\"Original: %s \\nPredicted: %s\" % (class_names[k], class_names[pred_classes[k]]))\n",
    "        ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "plot_actual_predicted(images_dict, predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use SHAP Deep Explainers to explain our model. First we will need to create a background set for SHAP and then compute Shapley values using Deep SHAP and visualize the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Setting the backgroud for shap\n",
    "background = x_train[np.random.choice(len(x_train), 1000, replace=False)]\n",
    "\n",
    "# DeepExplainer to explain predictions of the model\n",
    "explainer = shap.DeepExplainer(model, background)\n",
    "\n",
    "# Computing the shap values\n",
    "shap_values = explainer.shap_values(sample_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Prepare the labels for display\n",
    "labels = []\n",
    "for i in range(10):\n",
    "    labels.append(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "shap.image_plot(shap_values, sample_x_test, labels, labelpad=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was interesting to see how regions highlighted by SHAP values in red was actually related to the prediction class. I recommend looking at other tutorial examples provided by SHAP at https://github.com/slundberg/shap/tree/master/notebooks/image_examples and https://github.com/slundberg/shap/tree/master/notebooks/text_examples for applying SHAP with deep learning models trained on image and text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SHAP GitHub Project - https://github.com/slundberg/shap\n",
    "2. SHAP Documentations - https://shap.readthedocs.io/en/latest/index.html\n",
    "3. SHAP Image Explainers - https://github.com/slundberg/shap/tree/master/notebooks/image_examples/image_classification\n",
    "4. DeepExplainer Reference - \"Deep Learning Model Interpretation Using SHAP\" - https://towardsdatascience.com/deep-learning-model-interpretation-using-shap-a21786e91d16\n",
    "4. Some of the utility functions and code are taken from the GitHub Repository of the author - Aditya Bhattacharya https://github.com/adib0073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
